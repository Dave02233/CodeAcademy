# Dipendenza e Indipendenza nella Statistica

## üìù Notazione Matematica e Simboli

Prima di iniziare, ecco i simboli matematici usati nel documento:

| Simbolo | Significato | Esempio |
|---------|------------|---------|
| **$A \cap B$** | **Intersezione** - Entrambi gli eventi si verificano (AND) | Testa E numero 6 |
| **$A \mid B$** (o A\|B) | **Probabilit√† Condizionata** - Probabilit√† di $A$ sapendo che $B$ √® vero | Probabilit√† di testa se so che il dado √® 6 |
| **$P(A)$** | **Probabilit√†** di evento $A$ | $P(\text{Testa}) = 0.5$ |
| **$\cdot$** | **Moltiplicazione** | $P(A) \cdot P(B)$ |
| **$\neq$** | **Non uguale a** | $P(A \cap B) \neq P(A)$ |
| **$=$** | **Uguale a** | $P(A) = 0.5$ |

### A|B - Probabilit√† Condizionata

$P(A|B)$ si legge: **"Probabilit√† di A dato B"** oppure **"Probabilit√† di A condizionata a B"**

Significa: *Quale √® la probabilit√† che accada A sapendo gi√† che B √® accaduto?*

**Esempio pratico:**
- $P(\text{Pioggia})$ = probabilit√† piova (senza ulteriori informazioni)
- $P(\text{Pioggia} \| \text{Cielo nuvoloso})$ = probabilit√† piova sapendo che il cielo √® nuvoloso (√® pi√π alta!)

---

## Indipendenza Statistica

Due eventi $A$ e $B$ si dicono **statisticamente indipendenti** quando il verificarsi di uno di essi non influenza la probabilit√† che si verifichi l'altro.

### Definizione Matematica

Due eventi $A$ e $B$ sono **indipendenti** se:

$$P(A \cap B) = P(A) \cdot P(B)$$

In altre parole, la probabilit√† che si verifichino entrambi gli eventi √® il prodotto delle loro probabilit√† individuali.

### Propriet√† Equivalenti

Se $A$ e $B$ sono indipendenti, allora:

- $P(A|B) = P(A)$ (la probabilit√† di $A$ dato $B$ √® uguale a $P(A)$)
- $P(B|A) = P(B)$ (la probabilit√† di $B$ dato $A$ √® uguale a $P(B)$)

### Esempio

Lanciare una moneta e lanciare un dado sono eventi **indipendenti**:
- Che esca testa o croce dalla moneta non influenza il risultato del dado
- $P(\text{Testa}) = 0.5$
- $P(\text{6 sul dado}) = \frac{1}{6}$
- $P(\text{Testa e 6}) = 0.5 \times \frac{1}{6} = \frac{1}{12}$

---

## Dipendenza Statistica

Due eventi $A$ e $B$ si dicono **statisticamente dipendenti** quando il verificarsi di uno di essi **influenza** la probabilit√† che si verifichi l'altro.

### Definizione Matematica

Due eventi $A$ e $B$ sono **dipendenti** quando:

$$P(A \cap B) \neq P(A) \cdot P(B)$$

In questo caso, la probabilit√† congiunta non √® il semplice prodotto delle probabilit√† marginali.

### Propriet√† Equivalenti

Se $A$ e $B$ sono dipendenti, allora almeno una delle seguenti condizioni √® vera:

- $P(A|B) \neq P(A)$
- $P(B|A) \neq P(B)$

### Esempio

Estrarre due carte da un mazzo senza reinserimento sono eventi **dipendenti**:
- La prima estrazione modifica il numero di carte rimaste nel mazzo
- $P(\text{Asso alla 1¬™ estrazione}) = \frac{4}{52}$
- $P(\text{Asso alla 2¬™ | Asso alla 1¬™}) = \frac{3}{51} \neq \frac{4}{52}$

La probabilit√† cambia perch√© il mazzo √® stato modificato dalla prima estrazione.

---

## Probabilit√† Condizionata

La probabilit√† condizionata √® fondamentale per capire la dipendenza:

$$P(A|B) = \frac{P(A \cap B)}{P(B)}$$

Se $P(A|B) = P(A)$, allora $A$ e $B$ sono **indipendenti**.

---

## Tabella Comparativa

| Propriet√† | Indipendenti | Dipendenti |
|-----------|------------|-----------|
| **Formula** | $P(A \cap B) = P(A) \cdot P(B)$ | $P(A \cap B) \neq P(A) \cdot P(B)$ |
| **Condizionata** | $P(A\|B) = P(A)$ | $P(A\|B) \neq P(A)$ |
| **Effetto** | Un evento non influenza l'altro | Un evento influenza l'altro |
| **Esempio** | Moneta e dado | Estrarre carte senza reinserimento |

---

## Casi Pratici in Machine Learning

### Indipendenza: Vantaggi
- Semplifica i calcoli probabilistici
- Usata nel **Naive Bayes** che assume indipendenza tra le feature
- Riduce la complessit√† computazionale

### Dipendenza: Sfide
- Richiede calcoli pi√π complessi (probabilit√† condizionate)
- Necessita di pi√π dati per stimare le relazioni
- Importante considerarla nella selezione delle feature

---

## Indipendenza Condizionata

Due variabili possono essere **dipendenti**, ma diventare **indipendenti** dato un terzo evento $C$.

### Formula

$$P(A \cap B | C) = P(A|C) \cdot P(B|C)$$

### Esempio

- Et√† e stipendio sono generalmente **dipendenti**
- Ma se fissiamo il "settore industriale" ($C$), possono diventare condizionatamente **indipendenti** (lo stipendio dipende pi√π dal settore che dall'et√†)

---

## Riepilogo

‚úÖ **Indipendenti**: Verificarsi dell'uno NON influenza l'altro  
‚ùå **Dipendenti**: Verificarsi dell'uno INFLUENZA l'altro  
üîó **Indipendenza Condizionata**: Sono indipendenti dato un terzo evento
